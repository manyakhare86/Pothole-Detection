# -*- coding: utf-8 -*-
"""pothole detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GbSkfXrNUsEgwlaVrzYmCqYmgFKw3wg2

# Installing Detectron2
"""

import torch
print(torch.__version__)

!python -m pip install pyyaml==5.1
import sys, os, distutils.core
# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).
# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions
!git clone 'https://github.com/facebookresearch/detectron2'
dist = distutils.core.run_setup("./detectron2/setup.py")
!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}
sys.path.insert(0, os.path.abspath('./detectron2'))

# Properly install detectron2. (Please do not install twice in both ways)
# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

"""# Checking installation"""

import torch, detectron2
!nvcc --version
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
print("detectron2:", detectron2.__version__)

"""# Importing Libraries"""

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

"""# Make folders for images dataset"""

!unzip img.zip -d img

!unzip dataset.zip -d dataset

from detectron2.data.datasets import register_coco_instances
register_coco_instances("experiment", {}, "/content/output.json", "/content/img")

sample_metadata = MetadataCatalog.get("experiment")
dataset_dicts = DatasetCatalog.get("experiment")

"""# Vizualize Annotations"""

import random

for d in random.sample(dataset_dicts, 4):
    img = cv2.imread(d["file_name"])
    if img is not None:
        visualizer = Visualizer(img[:, :, ::-1], metadata=sample_metadata, scale=0.5)
        vis = visualizer.draw_dataset_dict(d)
        cv2_imshow(vis.get_image()[:, :, ::-1])

!git clone https://github.com/facebookresearch/detectron2 detectron2_repo

"""# Training Detectron2"""

from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
import os

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("experiment",)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")# initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.02
cfg.SOLVER.MAX_ITER = 200   # 300 iterations seems good enough, but you can certainly train longer
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # 3 classes (Person, Helmet, Car)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=True)
trainer.train()

from detectron2.data import detection_utils

class CustomDatasetMapper:
    def __init__(self, cfg, is_train=True):
        self.tfm_gens = detection_utils.build_transform_gen(cfg, is_train)

    def __call__(self, dataset_dict):
        dataset_dict = copy.deepcopy(dataset_dict)
        try:
            image = utils.read_image(dataset_dict["file_name"], format="BGR")
            transform_list = self.tfm_gens.get_transform(image)
            image, transforms = transform_list.apply_image(image)
        except FileNotFoundError:
            return None

        dataset_dict["image"] = torch.as_tensor(image.transpose(2, 0, 1).astype("float32"))
        if "annotations" in dataset_dict:
            annos = [detection_utils.transform_instance_annotations(obj, transforms, image.shape[:2])
                     for obj in dataset_dict.pop("annotations") if obj.get("iscrowd", 0) == 0]
            dataset_dict["instances"] = utils.annotations_to_instances(annos, image.shape[:2])
        return dataset_dict

# Use the custom dataset mapper in the trainer
cfg.DATASETS.TRAIN = ("experiment",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.02
cfg.SOLVER.MAX_ITER = 200
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

# Create a COCO Evaluator
evaluator = COCOEvaluator("experiment", cfg, False, output_dir="./output/")

# Perform inference on the test dataset
test_loader = build_detection_test_loader(cfg, "experiment")
inference_on_dataset(trainer.model, test_loader, evaluator)

# Print the evaluation results
print(evaluator.evaluate())

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

# Create a COCO Evaluator
evaluator = COCOEvaluator("experiment", cfg, False, output_dir="./output/")

# Perform inference on the test dataset
test_loader = build_detection_test_loader(cfg, "experiment")
results = inference_on_dataset(trainer.model, test_loader, evaluator)

# Extract the metrics
metrics = results["bbox"]

# Print the metrics
print(f"Mean Average Precision (mAP): {metrics['AP']}")
print(f"AP50: {metrics['AP50']}")
print(f"AP75: {metrics['AP75']}")
print(f"APs: {metrics['APs']}")
print(f"APm: {metrics['APm']}")
print(f"APl: {metrics['APl']}")

metrics = evaluator._results

# Calculate mAP in percentage
mAP_percentage = metrics["bbox"]["AP"]
print(f"Mean Average Precision (mAP): {mAP_percentage:.2f}%")

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %load_ext tensorboard
# %tensorboard --logdir output

"""# Saving cfg"""

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model
cfg.DATASETS.TEST = ("experiment",)
predictor = DefaultPredictor(cfg)

"""# Vizualizing for testing Model"""

from detectron2.utils.visualizer import ColorMode

for d in random.sample(dataset_dicts, 4):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=sample_metadata,
                   scale=0.8,
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(v.get_image()[:, :, ::-1])

"""# Save model in yaml format"""

f= open("config1.yaml","w")
f.write(cfg.dump())
f.close()

